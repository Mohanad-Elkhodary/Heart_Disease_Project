{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca52b81-1809-40ba-a256-7e75ef116ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in train: False\n",
      "NaN in test: False\n",
      "Inf in train: False\n",
      "Inf in test: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "#load\n",
    "X_train = np.load(\"X_train.npy\",allow_pickle=True)\n",
    "X_test = np.load(\"X_test.npy\",allow_pickle=True)\n",
    "Y_train = np.load(\"Y_train.npy\",allow_pickle=True)\n",
    "Y_test = np.load(\"Y_test.npy\",allow_pickle=True)\n",
    "# Logistic Regression\n",
    "param_grid_lr = {\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"penalty\": [\"l1\", \"l2\"],        # keep it simple (avoid elasticnet issues)\n",
    "    \"solver\": [\"liblinear\", \"saga\"] # both support l1 & l2\n",
    "}\n",
    "\n",
    "# SVM\n",
    "param_grid_svm = {\n",
    "    \"C\": [0.1, 1, 10],        \n",
    "    \"gamma\": [0.01, 0.1],      \n",
    "    \"kernel\": [\"linear\", \"rbf\"]  \n",
    "}\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "# Decision Tree\n",
    "param_grid_dt = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "# i have got a warning in the random forest so this step is to check and clean \n",
    "# If X_train is a DataFrame\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    X_train = X_train.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    X_test = X_test.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# If it's a NumPy array with object dtype\n",
    "if isinstance(X_train, np.ndarray) and X_train.dtype == \"object\":\n",
    "    X_train = X_train.astype(float)\n",
    "    X_test = X_test.astype(float)\n",
    "\n",
    "# Double check for NaN/inf\n",
    "print(\"NaN in train:\", np.isnan(X_train).any())\n",
    "print(\"NaN in test:\", np.isnan(X_test).any())\n",
    "print(\"Inf in train:\", np.isinf(X_train).any())\n",
    "print(\"Inf in test:\", np.isinf(X_test).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a890ce9-fa63-4199-9fe4-0bf5705ad699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Logistic Regression ðŸ”¹\n",
      "Best (GridSearchCV): {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.8152173913043478\n",
      "Best (RandomizedSearchCV): {'solver': 'liblinear', 'penalty': 'l1', 'C': 1}\n",
      "Accuracy: 0.8097826086956522\n",
      "\n",
      "ðŸ”¹ Random Forest ðŸ”¹\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dodoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best (GridSearchCV): {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.8478260869565217\n",
      "Best (RandomizedSearchCV): {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 10, 'bootstrap': False}\n",
      "Accuracy: 0.8586956521739131\n",
      "\n",
      "ðŸ”¹ Decision Tree ðŸ”¹\n",
      "Best (GridSearchCV): {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Accuracy: 0.7391304347826086\n",
      "Best (RandomizedSearchCV): {'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 5, 'criterion': 'gini'}\n",
      "Accuracy: 0.7608695652173914\n",
      "\n",
      "ðŸ”¹ SVM ðŸ”¹\n",
      "Best (GridSearchCV): {'C': 10, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "Accuracy: 0.8206521739130435\n",
      "Best (RandomizedSearchCV): {'kernel': 'linear', 'gamma': 0.1, 'C': 10}\n",
      "Accuracy: 0.8206521739130435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary of models and param grids\n",
    "models = {\n",
    "    \"Logistic Regression\": (LogisticRegression(max_iter=1000), param_grid_lr),\n",
    "    \"Random Forest\": (RandomForestClassifier(random_state=42), param_grid_rf),\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(random_state=42), param_grid_dt),\n",
    "    \"SVM\": (SVC(probability=True), param_grid_svm)\n",
    "}\n",
    "\n",
    "for name, (model, param_grid) in models.items():\n",
    "    print(f\"\\nðŸ”¹ {name} ðŸ”¹\")\n",
    "    \n",
    "    # GridSearchCV\n",
    "    grid = GridSearchCV(model, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid.fit(X_train, Y_train)\n",
    "    print(\"Best (GridSearchCV):\", grid.best_params_)\n",
    "    print(\"Accuracy:\", grid.score(X_test, Y_test))\n",
    "    \n",
    "    # RandomizedSearchCV\n",
    "    rand = RandomizedSearchCV(model, param_grid, n_iter=10, cv=5, scoring=\"accuracy\", n_jobs=-1, random_state=42)\n",
    "    rand.fit(X_train, Y_train)\n",
    "    print(\"Best (RandomizedSearchCV):\", rand.best_params_)\n",
    "    print(\"Accuracy:\", rand.score(X_test, Y_test))\n",
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22970e48-f630-4e9b-beda-59ee6b1dc170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Random Forest Accuracy: 0.8586956521739131\n",
      "\n",
      "Confusion Matrix:\n",
      " [[62 13]\n",
      " [13 96]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        75\n",
      "           1       0.88      0.88      0.88       109\n",
      "\n",
      "    accuracy                           0.86       184\n",
      "   macro avg       0.85      0.85      0.85       184\n",
      "weighted avg       0.86      0.86      0.86       184\n",
      "\n",
      "Model saved as final_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# model export\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "best_params_rf={'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 10, 'bootstrap': False}\n",
    "# Train final model\n",
    "final_model = RandomForestClassifier(**best_params_rf, random_state=42)\n",
    "final_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = final_model.predict(X_test)\n",
    "accuracy = final_model.score(X_test, Y_test)\n",
    "print(\"Final Random Forest Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(Y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(Y_test, y_pred))\n",
    "#exporting model\n",
    "joblib.dump(final_model, \"final_model.pkl\")\n",
    "print(\"Model saved as final_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e6a6de7-af15-4528-9d3d-4d4e017a8dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline accuracy: 0.8586956521739131\n",
      "pipeline saved as final_pipeline.pk1\n"
     ]
    }
   ],
   "source": [
    "#exporting pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Final chosen features\n",
    "final_feature = [\n",
    "    'thalch', 'age', 'oldpeak', 'chol', 'sex_Male',\n",
    "    'cp_non-anginal', 'fbs', 'cp_typical angina',\n",
    "    'restecg_st-t abnormality', 'exang',\n",
    "    'slope_upsloping', 'cp_atypical angina'\n",
    "]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"scaler\", StandardScaler(), final_feature)\n",
    "], remainder=\"drop\") \n",
    "\n",
    "# Pipeline with your tuned Random Forest\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=4,\n",
    "        bootstrap=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "X_train = pd.DataFrame(X_train, columns=final_feature)\n",
    "X_test = pd.DataFrame(X_test, columns=final_feature)\n",
    "# Fit on your training set\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Pipeline accuracy:\", pipeline.score(X_test, Y_test))\n",
    "#saving\n",
    "joblib.dump(pipeline, \"final_pipeline.pkl\")\n",
    "print(\"pipeline saved as final_pipeline.pk1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec4fae-f6e8-438d-81cb-3b99a62854eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
